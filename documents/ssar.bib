@inproceedings{mokaram2017,
author = {Mokaram, Saeid and Moore, Roger K .},
booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
title = {The Sheffield Search and Rescue Corpus},
pages = {5840--5844},
abstract = {As part of an ongoing research into extracting mission-critical information from Search and Rescue speech communications, a corpus of unscripted, goal-oriented, two-party spoken con- versations has been designed and collected. The Sheffield Search and Rescue (SSAR) corpus comprises about 12 hours of data from 96 conversations by 24 native speakers of British English with a southern accent. Each conversation is about a collaborative task of exploring and estimating a simulated in- door environment. The task has carefully been designed to have a quantitative measure for the amount of exchanged in- formation about the discourse subject. SSAR includes differ- ent layers of annotations which should be of interest to re- searchers in a wide range of human/human conversation un- derstanding as well as automatic speech recognition. It also provides an amount of data for analysis of multiple parallel conversations around a single subject. The SSAR corpus is available for research purposes.},
publisher = {IEEE},
address = {New Orleans},
month={March},
year = {2017},
}
